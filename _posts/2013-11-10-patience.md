---
layout:	post
title:	 Patience VS Efficiency
comments: yes
category: Bioinformatics
tags:	[NCBI, PubMed, Download, Abstract, Python, E-utilities]
---

It seems patience is a luxury for people of computer science.
I always picturing a scenery that a perfect script (suppose it is $S$) could finish a bioinformatics mission thoroughly from the downloading raw data to visualizing the result, even generating the .eps perfectly fit to the pdf paper.
I find every time i try to use the "fast" way, the progress curve seems being like red one in this image, 

 <img src="https://qoxlja.blu.livefilestore.com/y2p7u4TFiJdUmlHIdgbOP5SiDcwin1FD35L8TqYrASHso7HIVYN89aGgyYnH-nJjeZ2OUX5NYkmPXIVESZ2ATBwvb_BP8NKqajU-WQ-Agw3o0I/pic1.jpg"  alt="time VS progress image" width = 400 />

At the beginning, it is plausibly promising and progresses exponentially, but soon a stall looming, then I am going to waste a lot of time to address the problem and revise the code, even though the conservative solution (blue line) has already caught up with the "fast" solution, i still wish the "fast" solution will hopefully beat the conservative solution soon. 

It was like,to try to make a $S$ is stupid, the idea to finish all the tedious and repetitive work simply by clicking one button is irrational as well.
For instance, my workmate and I planned to download 1 million PubMed XML entries as raw data for literature mining.
Intuitively, we got a multi-threading python script developed soon, threshold of threads was primarily set at 500, everything seemed fine, except IP of our lab got blocked in a  short while. 
Then we began to browse NCBI ftp folder by folder, read every `readme`  file, we thought this big data was stored at somewhere in NCBI ftp. But the problem is if we send a email consult NCBI how to download big data at the very beginning, then we will already finish the job..

Here is the advice from supervisor of NCBI web page,
> NCBI's main mission is to provide interactive web access to our data.
> Scripts push users off the web servers and limit the access of interactive users.
> Scripts should not be written against web servers with out prior consultation with the admins of the servers.
> 
> - If you are searching PubMed or Entrez, please use the E-utilities if you
> have not already done so (http://www.ncbi.nlm.nih.gov/books/NBK25497).
> - Limit all scripts to the off peak hours of 9 PM to 5 AM Eastern Standard Time (USA).

